from typing import List

import tiktoken, discord
from openai import AsyncOpenAI

from constants import LLMModel
from llm.base_llm import LLM


class GPT(LLM):
    """A class to encapsulate OpenAI GPT related functionalities."""

    def __init__(self, api_key):
        super().__init__()
        self.client = AsyncOpenAI(api_key=api_key)

    async def communicate(self, history: List[discord.Message],
                          model: LLMModel,
                          temperature: float,
                          top_p: float,
                          system_message: str) -> str:
        """
        Communicates with a language model using a Discord thread using.
        Args:
            history (List[discord.Message]): The Discord message history to use for the communication.
            model (LLMModel): The language model to use for generating responses.
            temperature (float): Controls the randomness of the responses. Higher values result in more randomness.
            top_p (float): Top-p nucleus sampling parameter.
            system_message (str): The system message to include in the communication.
        Returns:
            str: The response generated by the language model.
        """
        messages = await self.collect_payload(history, model, system_message)
        response = await self.client.chat.completions.create(
            model=model.version,
            messages=messages,
            temperature=temperature,
            top_p=top_p,
            max_tokens=4096 if model == LLMModel.GPT_4_VISION else None
        )
        gpt_response = response.choices[0].message.content
        return gpt_response

    async def _calculate_tokens(self, content: list[dict[str, str]], model: LLMModel) -> int:
        """
        Calculates the number of tokens required to process a message.
        Args:
            content (list[dict[str, str]]): the content to process.
        Returns:
            num_tokens (int): the number of tokens required to process the content.
        """
        try:
            encoding = tiktoken.encoding_for_model(model.version)
            tokens = 0
            for entry in content:
                if entry['type'] == 'text':
                    tokens += len(encoding.encode(entry['text']))
                elif entry['type'] == 'image_url':
                    """TODO: Calculate image tokens as per 
                    https://platform.openai.com/docs/guides/vision/calculating-costs"""
                    pass
            return tokens
        except KeyError:
            raise NotImplementedError(
                f'_calculate_tokens() is not presently implemented for model {model.version}'
            )
